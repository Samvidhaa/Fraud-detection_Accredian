{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b3d648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
      "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
      "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
      "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
      "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "0  M1979787155             0.0             0.0        0               0  \n",
      "1  M2044282225             0.0             0.0        0               0  \n",
      "2   C553264065             0.0             0.0        1               0  \n",
      "3    C38997010         21182.0             0.0        1               0  \n",
      "4  M1230701703             0.0             0.0        0               0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"C:/Users/samvi/OneDrive/Desktop/samvidhaa/Fraud.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4569d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef077a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning\n",
    "# Handle missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a7d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers\n",
    "# For simplicity, let's winsorize the data to deal with outliers in numerical columns\n",
    "from scipy.stats.mstats import winsorize\n",
    "numeric_cols = ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "df[numeric_cols] = df[numeric_cols].apply(lambda x: winsorize(x, limits=[0.01, 0.01]), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ad2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Engineering\n",
    "# Select relevant features\n",
    "X = df[['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "y = df['isFraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e422a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Multicollinearity Assessment\n",
    "# Check for multicollinearity using correlation matrix\n",
    "correlation_matrix = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e185004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5fbc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d7c4d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Model Training\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3477526a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1270904\n",
      "           1       0.89      0.42      0.57      1620\n",
      "\n",
      "    accuracy                           1.00   1272524\n",
      "   macro avg       0.95      0.71      0.79   1272524\n",
      "weighted avg       1.00      1.00      1.00   1272524\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1270823      81]\n",
      " [    941     679]]\n",
      "Accuracy: 0.9991968717289419\n",
      "AUC-ROC Score: 0.9444775143723885\n"
     ]
    }
   ],
   "source": [
    "# 8. Model Evaluation\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# AUC-ROC score\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:,1]\n",
    "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a5de37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n1. Data cleansing with multi-collinearity, outliers, and missing values:\\n\\nMissing Values: As the line df.dropna(inplace=True) indicates, any rows containing missing values will be dropped as part of the data cleaning procedure.\\nOutliers: Winsorization is used to handle outliers with a 1% trimming limit.\\nMulticollinearity: A correlation matrix (correlation_matrix) computed on the feature variables is\\xa0used to evaluate multicollinearity.\\n\\n\\n2. Describe your fraud detection model in elaboration.\\n\\nIn this instance, the binary classification approach known as logistic regression is employed as the fraud detection model.\\nBased on the chosen predictor variables (features), logistic regression models the likelihood of a binary result (fraudulent or non-fraudulent transaction). The log odds of the event's likelihood are computed by the model.\\n\\n\\n3. How did you select variables to be included in the model?\\n\\nStep, amount, oldbalanceOrg, newbalanceOrig, oldbalanceDest, and newbalanceDest are the variables chosen for the model. \\nThese characteristics were picked because they may be useful in differentiating between transactions that are fraudulent and those that are not.\\n\\n\\n4. Demonstrate the performance of the model by using best set of tools. \\n\\nAccuracy, precision, recall, F1-score, confusion matrix, and AUC-ROC score are among the performance indicators provided. \\nThese indicators offer valuable insights into the model's performance with respect to accurately detecting fraudulent transactions.\\n\\n\\n5. What are the key factors that predict fraudulent customer?\\n\\nThe primary variables predicting fraudulent transactions are not specifically stated, according to the model's success metrics. \\nNevertheless, transaction amounts, account balances prior to and following transactions, transaction kinds, and maybe the timing of the transaction (step) are examples of common critical elements.\\n\\n\\n6. Do these factors make sense? If yes, How? If not, How not? \\n\\nIndeed, these factors are logical. \\nIn contrast to authentic transactions, fraudulent transactions may contain odd transaction amounts, abrupt changes in account balances, certain transaction types (like transfers), and distinct patterns. \\nThese elements are consistent with traits of dishonest behavior.\\n\\n\\n7. What kind of prevention should be adopted while company update its infrastructure?\\n\\nImplementing sophisticated anomaly detection algorithms, improving authentication methods (like multi-factor authentication), keeping an eye on real-time transaction patterns, and enforcing stringent restrictions over high-risk transactions (such large transfers) are a few examples of preventive measures.\\n\\n\\n8. Assuming these actions have been implemented, how would you determine if they work?\\n\\nBy keeping an eye on key performance metrics like the decline in false positive rates, the number of fraudulent transactions, the improvement in model accuracy and AUC-ROC score, and the capacity to identify novel forms of fraudulent activity, one can assess the efficacy of preventative measures. \\nContinuous evaluation and enhancement of the fraud detection system would also require regular audits and assessments of its operation.\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "1. Data cleansing with multi-collinearity, outliers, and missing values:\n",
    "\n",
    "Missing Values: As the line df.dropna(inplace=True) indicates, any rows containing missing values will be dropped as part of the data cleaning procedure.\n",
    "Outliers: Winsorization is used to handle outliers with a 1% trimming limit.\n",
    "Multicollinearity: A correlation matrix (correlation_matrix) computed on the feature variables isÂ used to evaluate multicollinearity.\n",
    "\n",
    "\n",
    "2. Describe your fraud detection model in elaboration.\n",
    "\n",
    "In this instance, the binary classification approach known as logistic regression is employed as the fraud detection model.\n",
    "Based on the chosen predictor variables (features), logistic regression models the likelihood of a binary result (fraudulent or non-fraudulent transaction). The log odds of the event's likelihood are computed by the model.\n",
    "\n",
    "\n",
    "3. How did you select variables to be included in the model?\n",
    "\n",
    "Step, amount, oldbalanceOrg, newbalanceOrig, oldbalanceDest, and newbalanceDest are the variables chosen for the model. \n",
    "These characteristics were picked because they may be useful in differentiating between transactions that are fraudulent and those that are not.\n",
    "\n",
    "\n",
    "4. Demonstrate the performance of the model by using best set of tools. \n",
    "\n",
    "Accuracy, precision, recall, F1-score, confusion matrix, and AUC-ROC score are among the performance indicators provided. \n",
    "These indicators offer valuable insights into the model's performance with respect to accurately detecting fraudulent transactions.\n",
    "\n",
    "\n",
    "5. What are the key factors that predict fraudulent customer?\n",
    "\n",
    "The primary variables predicting fraudulent transactions are not specifically stated, according to the model's success metrics. \n",
    "Nevertheless, transaction amounts, account balances prior to and following transactions, transaction kinds, and maybe the timing of the transaction (step) are examples of common critical elements.\n",
    "\n",
    "\n",
    "6. Do these factors make sense? If yes, How? If not, How not? \n",
    "\n",
    "Indeed, these factors are logical. \n",
    "In contrast to authentic transactions, fraudulent transactions may contain odd transaction amounts, abrupt changes in account balances, certain transaction types (like transfers), and distinct patterns. \n",
    "These elements are consistent with traits of dishonest behavior.\n",
    "\n",
    "\n",
    "7. What kind of prevention should be adopted while company update its infrastructure?\n",
    "\n",
    "Implementing sophisticated anomaly detection algorithms, improving authentication methods (like multi-factor authentication), keeping an eye on real-time transaction patterns, and enforcing stringent restrictions over high-risk transactions (such large transfers) are a few examples of preventive measures.\n",
    "\n",
    "\n",
    "8. Assuming these actions have been implemented, how would you determine if they work?\n",
    "\n",
    "By keeping an eye on key performance metrics like the decline in false positive rates, the number of fraudulent transactions, the improvement in model accuracy and AUC-ROC score, and the capacity to identify novel forms of fraudulent activity, one can assess the efficacy of preventative measures. \n",
    "Continuous evaluation and enhancement of the fraud detection system would also require regular audits and assessments of its operation.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
